在应用系统开发过程中，我们经常会用到池化技术，比如对象池、连接池、线程池等，通过池化来减少一些消耗，以提升性能。对象池通过复用对象从而减少创建对象、垃圾回收的开销，但是，池不能太大，太大会影响GC时扫描的时间。连接池如数据库连接池、Redis连接池、HTTP连接池，通过复用TCP连接来减少创建和释放连接的时间来提升性能。线程池也是类似的，通过复用线程提升性能。不管是对象、TCP连接、还是线程都是稀缺资源，池化技术就是通过复用技术以提升性能。



今天，我要说的是另一种池化技术——锁池。



在分布式系统下，通常会使用锁来保证操作的一致性。同时会存在锁竞争的情况，这种情况会随着外部请求量的激增而变得更激烈。所以，一个改进的方向就是改变锁的细粒度，从简单的粗力度锁变为更适宜的细粒度锁。而细粒度的锁相比较粗力度来说虽然解决了流量激增带来的竞争激烈程度，但是，细粒度锁在实现上也增加了复杂度。原本一把锁就可搞定的事，现在要维护好多把锁，为了更好的维护更多的细粒度锁，这个时候池化技术就该出现了。

那到底锁的细粒度多少算合理，那就得先明确一下锁的细粒度级别。

通常，比较粗的粒度锁，全局单一控制锁，能够做到读写分离的程度就能满足，实现简单。但是，扩展性差点儿，容易达到性能瓶颈。

其次，稍微细粒度一点的锁，按照bucket进行分段的分段锁。这个也许大家都不陌生，`ConcurentHashMap`在1.7中对性能的优化上，`ConcurrentHashMap` 采用了分段锁技术，其中 `Segment` 继承于 `ReentrantLock`。不会像` HashTable` 那样不管是 put 还是 get 操作都需要做同步处理，理论上 `ConcurrentHashMap` 支持 `CurrencyLevel `(`Segment` 数组数量)的线程并发。每当一个线程占用锁访问一个 `Segment` 时，不会影响到其他的 `Segment`。在这种情况下，锁的数量还是能在一定数量控制之下。

最终，我们看看真正意义上的细粒度锁，它的细粒度在于可以控制到ID级别，或者每个数据块block级别这种类型。这个级别的锁，数量上可能就成千上万，甚至更大规模。如果这些锁都是存储在内存中，那么，将面临一个问题就是内存的急剧膨胀。

所以，锁池就应运而生。在有限的内存资源下，可以将锁的数量控制在一定规模。最关键的一点是，锁池内的锁被释放后，能被其他请求获取到而使用，达到锁复用的目的。但是，需基于一个前提：

>  即一定时间内，往往只同时存在一定数量的资源被操作，因此，我们只需维护这部分被操作的资源所需要的锁，而这个规模数量是有限的。

但是，我要说但是了！世上没有完美的解决方案，这种情况下会存在锁碰撞的发生，只不过是一个低概率事件。当系统同时在操作的单位数需要获取同一把锁的时候，此时就会发生锁等待的情形。当锁池内维护的锁总数量越多的时候，碰撞概率就越低。

然后，回到`GooseFS`的锁池实现。在`InodeLockManager`中有三种实现方式：

- 第一种，是自我实现的`LockPool`方式，比如：mInodeLocks、mEdgeLocks

- 第二种，使用了Striped类做细粒度级别锁的控制：`private final Striped<Lock> mParentUpdateLocks = Striped.lock(1_000);`

- 第三种，`LoadingCache<Long, AtomicBoolean> mPersistingLocks` ，该锁池使用的是weakValues

